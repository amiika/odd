# How to FZRTH: Samples & Mininotation

[Last time](../source/0002.html), we built a rhythmic engine that could play sine waves and use Forth like operators to create sequences, cycles and chords.

Next we are upgrading the engine significantly by adding more waveforms and support for samples and adopting some of the philosophy from other **"Uzulangs"**.

## 1. Mininotation

Live coding languages like the TidalCycles often prioritize terseness and cognitive speed. You want to type something that *feels* and *looks* like the rhythm it plays. We are borrowing some of the **Mininotation** concept from TidalCycles and the **Bol Processor**.

## 2. Syntax Sugar & The Compiler

To support this mininotation, we add shorthand operators to our dictionary.

* `[ ... ]` -> **Sequence**: Divides a beat into equal parts.
* `< ... >` -> **Cycle**: Spans across multiple beats.
* `( ... )` -> **Chord**: Plays simultaneously.

## 1. Syntax Sugar & The Compiler

Writing `10 20 30 seq` is classic Forth, but `[ 10 20 30 ]` is easier to read and makes it possible to do recursive containers. To support this, we add `marker` operators to our dictionary. When the interpreter sees `[`, it pushes a marker (`SEQ`) onto the stack. When it sees `]`, it pops everything off the stack until it finds that marker, wraps it in a data structure, and pushes it back.

```javascript
// Inside DICT...
'seq':   (c) => collapseAll(c, SEQ),
'cycle': (c) => collapseAll(c, CYC),
'chord': (c) => collapseAll(c, CHO),

// Shorthands
'[': (c) => c.stack.push(SEQ), ']': (c) => closeGroup(c, SEQ), // Sequence
'<': (c) => c.stack.push(CYC), '>': (c) => closeGroup(c, CYC), // Cycle
'(': (c) => c.stack.push(CHO), ')': (c) => closeGroup(c, CHO), // Chord
```

The `closeGroup` helper effectively reverses the stack items found between the brackets so they stay in the correct order. 

## 2. The Sound Class: From Recursion to Iterators

In Part 2, we calculated the played frequency. In this section we also add standard waveforms (`saw`, `sqr`, `tri`) and a `play` operator for playing samples.

We also want to play patterns recursively to any level. To solve this we are changing the stateless model to use Sound class and use **JavaScript Generators** (`function*`).

We wrap every sound event in a `Sound` class. The `makeIterator` method walks through our rhythmic tree (nested arrays of sequences and cycles) and `yields` events only when they happen.

```javascript
class Sound {
    constructor(pattern, type) {
        this.pattern = pattern;
        this.type = type; // e.g. 'SINE' or 'SMP' (Sample)
        this.renderFn = RENDERERS[type];
        this.iter = this.makeIterator(); // The generator
        this.endTime = -1; 
        this.voices = [];
    }

    // Infinite loop that restarts the pattern when finished
    *makeIterator() { while(true) yield* this.visit(this.pattern, 1.0, 1.0); }

    // Recursive generator walking the tree
    *visit(node, duration, gain) {
        // SEQ: Divide duration by number of steps
        if (node?.type === SEQ) {
            const step = duration / (node.data.length || 1);
            for (const item of node.data) yield* this.visit(item, step, gain);
            return;
        }

        // CYCLE: Pick one item based on index, then increment
        if (node?.type === CYC) {
            if (node.data.length) {
                const idx = node.idx++ % node.data.length;
                yield* this.visit(node.data[idx], duration, gain);
            }
            return;
        }

        // We found a note! Yield it to the audio engine
        yield { nodes: [node], baseGain: gain, dur: duration };
    }
}
```

Now, the audio engine just asks the iterator: *"What is the next note, and how long does it last?"*

## 3. Sample Loading (Worklet vs Main Thread)

This is the tricky part. We are running inside an `AudioWorklet`. The Worklet is isolated and it cannot use `fetch()` to download audio files from the internet. 

We need a communication protocol:
1.  **Worklet:** Scans the code for strings (e.g., `"bd"`, `"cp"`).
2.  **Worklet:** Sends a message to the Main Thread: "I need 'bd'".
3.  **Main Thread:** Fetches the audio, decodes it, and sends the raw buffer back.
4.  **Worklet:** Stores the buffer in `this.samples`.

### The Worklet Scanner
When we compile code, we look for strings:

```javascript
function scanSamples(c, node) {
    if (typeof node === 'string') c.req.add(node); // Add to request Set
    else if (node.data) {
        // Recursively look inside sequences/chords
        if(Array.isArray(node.data)) node.data.forEach(n => scanSamples(c, n));
    }
}
```

### Loading samples

We will use the same Dirt samples and notation used by the [Tidalcycles](https://github.com/tidalcycles/Dirt-Samples). For now we use static url, but in the future we could also add operator to load strudel sample packs dynamically.

```javascript
// ... Inside the main thread (0003.html)
try {
    const ab = await fetch('https://raw.githubusercontent.com/tidalcycles/dirt-samples/master/' + path).then(r=>r.arrayBuffer());
    const aud = await audioCtx.decodeAudioData(ab);
    this.cache[reqKey] = true;
    // Send back with the original requested key (e.g., "h:3")
    port.postMessage({ type: 'sample', name: reqKey, buf: { data: aud.getChannelData(0), sr: aud.sampleRate, len: aud.length }});
} catch(e) { console.error("Sample load error:", e); }
```

### The Rendering Logic

Inside the audio loop, if the sound type is `SMP` (Sample), we use the received buffer data instead of wave formula.

```javascript
'SMP':  (p, buf) => {
    if (!buf) return 0;
    // Map phase (0.0 to 1.0) to buffer index
    const idx = Math.floor(p * buf.sr); 
    return (idx >= 0 && idx < buf.len) ? buf.data[idx] : 0;
}
```

## 4. The Demo

Now we can combine samples with our rhythmic operators. The following code creates a "cycle" (`< ... >`) where `bd` (bass drum) and `sd` (snare) alternate on the beat, while `hh` (hihat) and `cp` (clap) play faster inside a sequence.


```fzrth
135 bpm

[ bd sd < hh cp [h:4 h:4] > ] play

```

[Open full Version](./source/0003/0003.html)

We now have a functional sampler with a concise syntax. In the next Part we will look into visualizing the played code in the main thread.

[Back to Index](./index.html)


<details>
<summary>Full source</summary>


HTML:
```html
<!DOCTYPE html>
<html>
<head>
    <title>FZRTH - 0003</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body { background: #000; color: #fb0; font-family: monospace; display: flex; flex-direction: column; height: 100vh; margin: 0; overflow: hidden; }
        #editor { flex: 1; background: #000; color: #fb0; border: none; padding: 20px; font-size: 20px; outline: none; resize: none; width: 100%; box-sizing: border-box; }
        .header { font-size: 24px; padding: 15px; border-bottom: 1px solid #fb0; display: flex; justify-content: space-between; align-items: center; background: #111;}
        .status { font-size: 14px; color: #666; cursor: pointer; }
        .active { color: #fb0; }
        ::selection { background: #fb0; color: #000; }
    </style>
</head>
<body>
    <div class="header">
        <div>FZRTH</div>
        <div id="status" class="status">CLICK TO START</div>
    </div>

    <textarea id="editor" spellcheck="false">
120 bpm

: beat [ bd <sd <hh h:4>> ] play ;

beat</textarea>

<script>
    const editor = document.getElementById('editor');
    const status = document.getElementById('status'); 
    let audioCtx, node;

    const LOADER = {
        cache: {},
        map: null,
        async load(names, port) {
            if (!this.map) this.map = await fetch('https://raw.githubusercontent.com/tidalcycles/dirt-samples/master/strudel.json').then(r=>r.json());
            
            for(const reqKey of names) {
                if (this.cache[reqKey]) continue;

                // Split 'name:index' (e.g. "h:3" -> base="h", idx=3)
                // If no colon, use base name and index 0
                const [base, idxStr] = reqKey.split(':');
                const idx = idxStr ? parseInt(idxStr) : 0;
                
                const entry = this.map[base];
                if (!entry) { console.warn("Folder not found:", base); continue; }

                // Retrieve path. Strudel map can be Array or Object.
                let path;
                if (Array.isArray(entry)) {
                    path = entry[idx] || entry[0];
                } else {
                    const values = Object.values(entry);
                    path = values[idx] || values[0];
                }
                
                if (!path) { console.warn("Sample not found:", reqKey); continue; }
                
                try {
                    const ab = await fetch('https://raw.githubusercontent.com/tidalcycles/dirt-samples/master/' + path).then(r=>r.arrayBuffer());
                    const aud = await audioCtx.decodeAudioData(ab);
                    this.cache[reqKey] = true;
                    // Send back with the original requested key (e.g., "h:3")
                    port.postMessage({ type: 'sample', name: reqKey, buf: { data: aud.getChannelData(0), sr: aud.sampleRate, len: aud.length }});
                } catch(e) { console.error("Sample load error:", e); }
            }
        }
    };

    async function init() {
        if (audioCtx) return;
        if (!status) return;

        try {
            audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            status.innerText = "LOADING...";

            await audioCtx.audioWorklet.addModule('0003.js');

            node = new AudioWorkletNode(audioCtx, 'fzrth-proc');
            node.connect(audioCtx.destination);
            
            node.port.onmessage = (e) => { 
                if (e.data.type === 'req') LOADER.load(e.data.names, node.port); 
            };
            
            editor.addEventListener('input', () => node.port.postMessage(editor.value));
            
            node.port.postMessage(editor.value);
            status.innerText = "RUNNING";
            status.classList.add('active');

        } catch (e) { 
            console.error(e); 
            status.innerText = "ERROR";
            status.style.color = "red";
        }
    }
    
    document.addEventListener('click', init, { once: true });
</script>
</body>
</html>
```


AudioWorkletProcessor code:

```javascript
const SEQ='SEQ', CYC='CYC', CHO='CHO', SMP='SMP';

const DICT = {
    'sine': (c) => render(c, 'SINE'),
    'tri':  (c) => render(c, 'TRI'),
    'saw':  (c) => render(c, 'SAW'),
    'sqr':  (c) => render(c, 'SQR'),
    'play': (c) => render(c, SMP),
    'seq':   (c) => container(c, SEQ),
    'cycle': (c) => container(c, CYC),
    'chord': (c) => container(c, CHO),
    '[': (c) => c.stack.push(SEQ), ']': (c) => closeGroup(c, SEQ),
    '<': (c) => c.stack.push(CYC), '>': (c) => closeGroup(c, CYC),
    '(': (c) => c.stack.push(CHO), ')': (c) => closeGroup(c, CHO),
    ':': macro,
    'dup':  (c) => { if (c.stack.length) c.stack.push(c.stack[c.stack.length-1]); },
    'drop': (c) => c.stack.pop(),
    'swap': (c) => { const a=c.stack.pop(), b=c.stack.pop(); c.stack.push(a, b); },
    'bpm': (c) => { if(c.stack.length) c.bpm = resolve(c.stack.pop()); },
    '+': (c) => calc(c, (a,b)=>a+b),
    '-': (c) => calc(c, (a,b)=>a-b),
    '*': (c) => calc(c, (a,b)=>a*b),
    '/': (c) => calc(c, (a,b)=>a/b),
    '%': (c) => calc(c, (a,b)=>a%b),
};

function render(c, type) {
    if (c.stack.length === 0) return;
    const data = c.stack.splice(0);
    const pattern = data.length > 1 ? { type: SEQ, data } : data[0];
    if (type === SMP) scanSamples(c, pattern);
    c.sounds.push(new Sound(pattern, type));
}

function container(c, type) {
    const data = c.stack.splice(0);
    c.stack.push({ type, data, idx: 0 });
}

function closeGroup(c, marker) {
    const tmp = [];
    while (c.stack.length) {
        const item = c.stack.pop();
        if (item === marker) {
            c.stack.push({ type: marker, data: tmp.reverse(), idx: 0 });
            return;
        }
        tmp.push(item);
    }
}

function scanSamples(c, node) {
    if (!node) return;
    if (typeof node === 'string') c.req.add(node);
    else if (node.data) {
        if(Array.isArray(node.data)) node.data.forEach(n => scanSamples(c, n));
        else scanSamples(c, node.data);
    }
}

function macro(c) {
    const name = c.tokens[c.pos++];
    const body = [];
    while (c.pos < c.tokens.length) {
        const t = c.tokens[c.pos++];
        if (t === ';') break;
        body.push(t);
    }
    c.macros[name] = body;
}

function calc(c, fn) {
    if (c.stack.length < 1) return;
    const b = c.stack.pop();
    const a = (fn.length > 1 && c.stack.length > 0) ? c.stack.pop() : undefined;
    const map = (x, y) => {
        if (y?.data) return { ...y, data: y.data.map(i => map(x, i)) };
        if (x?.data) return { ...x, data: x.data.map(i => map(i, y)) };
        return { type: 'OP', fn, args: [x, y] };
    };
    c.stack.push(map(a, b));
}

function resolve(node) {
    if (typeof node === 'number') return node;
    if (typeof node === 'string') return node;
    if (!node) return 0;
    if (node.type === 'OP') return node.fn(resolve(node.args[0]), resolve(node.args[1]));
    return 0;
}

const RENDERERS = {
    'SINE': (p) => Math.sin(p * 6.28318),
    'TRI':  (p) => Math.abs((p % 1) * 4 - 2) - 1,
    'SAW':  (p) => (p % 1) * 2 - 1,
    'SQR':  (p) => (p % 1) < 0.5 ? 0.5 : -0.5,
    'SMP':  (p, buf) => {
        if (!buf) return 0;
        const idx = Math.floor(p * buf.sr);
        return (idx >= 0 && idx < buf.len) ? buf.data[idx] : 0;
    }
};

class Sound {
    constructor(pattern, type) {
        this.pattern = pattern;
        this.type = type;
        this.renderFn = RENDERERS[type];
        this.iter = this.makeIterator();
        this.endTime = -1;
        this.voices = [];
        this.curr = null;
    }

    *makeIterator() { while(true) yield* this.visit(this.pattern, 1.0, 1.0); }

    *visit(node, duration, gain) {
        if (node?.type === SEQ) {
            const step = duration / (node.data.length || 1);
            for (const item of node.data) yield* this.visit(item, step, gain);
            return;
        }
        if (node?.type === CYC) {
            if (node.data.length) yield* this.visit(node.data[node.idx++ % node.data.length], duration, gain);
            return;
        }
        if (node?.type === CHO) {
            const flatten = (n) => {
                if (n?.type === SEQ || n?.type === CHO || n?.type === CYC) return n.data.flatMap(flatten);
                return [n];
            };
            const allNotes = node.data.flatMap(flatten);
            yield { nodes: allNotes, baseGain: gain, dur: duration };
            return;
        }
        yield { nodes: [node], baseGain: gain, dur: duration };
    }
}

class ForthProcessor extends AudioWorkletProcessor {
    constructor() {
        super();
        this.sounds = [];
        this.samples = {};
        this.bpm = 120;
        
        this.lastBpm = 120;
        this.anchorFrame = 0;
        this.anchorBeat = 0;
        
        this.port.onmessage = (e) => {
            if (e.data.type === 'sample') this.samples[e.data.name] = e.data.buf;
            else this.compile(e.data);
        };
    }

    compile(text) {
        const tokens = text.match(/"[^"]*"|#.*|[^\s\[\]<>()]+|[\[\]<>()]/g) || [];
        const sampleRequests = new Set();
        const ctx = { 
            tokens: tokens.filter(t => !t.startsWith('#')), 
            pos: 0, 
            stack: [],
            sounds: [], 
            macros: {}, 
            bpm: this.bpm, 
            req: sampleRequests 
        };

        ctx.run = (list) => {
            const saveT = ctx.tokens, saveP = ctx.pos;
            ctx.tokens = list; ctx.pos = 0;
            while (ctx.pos < ctx.tokens.length) {
                const t = ctx.tokens[ctx.pos++];
                const num = parseFloat(t);
                
                if (!isNaN(num) && !t.includes(':')) {
                    ctx.stack.push(num);
                }
                else if (DICT[t]) DICT[t](ctx);
                else if (ctx.macros[t]) ctx.run(ctx.macros[t]);
                else ctx.stack.push(t);
            }
            ctx.tokens = saveT; ctx.pos = saveP;
        };

        try { ctx.run(ctx.tokens); } catch(e) {}
        this.sounds = ctx.sounds;
        this.bpm = ctx.bpm;
        if (sampleRequests.size) this.port.postMessage({ type: 'req', names: Array.from(sampleRequests) });
    }

    process(inputs, outputs) {
        const output = outputs[0][0];
        if (!output) return true;

        if (this.bpm !== this.lastBpm) {
            const prevRate = this.lastBpm / (60 * sampleRate);
            const beatNow = this.anchorBeat + (currentFrame - this.anchorFrame) * prevRate;
            this.anchorBeat = beatNow;
            this.anchorFrame = currentFrame;
            this.lastBpm = this.bpm;
        }

        const beatsPerSample = this.bpm / (60 * sampleRate);

        for (let i = 0; i < output.length; i++) {
            const absFrame = currentFrame + i;
            const beatNow = this.anchorBeat + (absFrame - this.anchorFrame) * beatsPerSample;
            
            let signal = 0;

            for (const snd of this.sounds) {
                if (snd.endTime === -1) {
                    snd.endTime = Math.floor(beatNow);
                }

                while (beatNow >= snd.endTime) {
                    const next = snd.iter.next();
                    snd.curr = next.value;
                    snd.endTime += next.value.dur;
                    if (snd.curr) {
                        snd.voices = snd.curr.nodes.map(() => ({ p: 0 }));
                    }
                }

                if (!snd.curr) continue;

                for (let v = 0; v < snd.curr.nodes.length; v++) {
                    const node = snd.curr.nodes[v];
                    const voice = snd.voices[v];
                    const gain = snd.curr.baseGain;
                    const val = resolve(node);

                    if (snd.type === SMP) {
                        if (typeof val === 'string' && this.samples[val]) {
                            signal += snd.renderFn(voice.p, this.samples[val]) * gain;
                            voice.p += (1/sampleRate);
                        }
                    } else {
                        if (val > 0) {
                            voice.p += (val / sampleRate);
                            signal += snd.renderFn(voice.p) * gain;
                        }
                    }
                }
            }
            output[i] = signal * 0.2;
        }
        return true;
    }
}
registerProcessor('fzrth-proc', ForthProcessor);
```

</details>